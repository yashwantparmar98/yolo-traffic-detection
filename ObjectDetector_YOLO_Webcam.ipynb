{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetector_YOLO_Webcam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nddL3NW31CK9",
        "colab_type": "code",
        "outputId": "213a54ee-4e12-48b5-ed76-458a8ca3e515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pdhruv93/YOLO-Object-Detection.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'YOLO-Object-Detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1tP_xUspJaK6",
        "colab_type": "code",
        "outputId": "796cca31-e2a6-45fd-abe7-c90404e3b2c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd YOLO-Object-Detection//yolo-object-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/YOLO-Object-Detection/yolo-object-detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XS917czhWi7W",
        "colab_type": "code",
        "outputId": "2e4342a9-e59b-4600-f49a-3afbd58f28c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://pjreddie.com/media/files/yolov3.weights\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-25 21:55:23--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  59.2MB/s    in 4.6s    \n",
            "\n",
            "2019-02-25 21:55:27 (52.0 MB/s) - ‘yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3qRaZzSDKZe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OX9Voz5VKaHi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yoloPath=\"yolo-coco\"\n",
        "#yolo --base path to YOLO directory\n",
        "#confidence --minimum probability to filter weak detections\n",
        "#threshold --threshold when applyong non-maxima suppression\n",
        "args={'yolo': yoloPath , 'confidence': 0.5, 'threshold': 0.3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0MSlvBYKfPn",
        "colab_type": "code",
        "outputId": "9d02d595-a25d-4f97-8465-956f540cc3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# load the COCO class labels our YOLO model was trained on\n",
        "LABELS = open(yoloPath+\"//coco.names\").read().strip().split(\"\\n\")\n",
        "print(\"Toal classes {0}\".format(len(LABELS)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Toal classes 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zjfwpEsIKjsD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize a list of colors to represent each possible class label\n",
        "np.random.seed(42)\n",
        "#create random list of int type numbers from range 0-255. Size = len(LABELS), 3... 3 is for RGB\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdEW-O_kKkq0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# derive the paths to the YOLO weights and model configuration\n",
        "weightsPath = \"yolov3.weights\"\n",
        "configPath = yoloPath+\"//yolov3.cfg\"\n",
        "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u301D1WbKmu7",
        "colab_type": "code",
        "outputId": "3a9d43e0-5371-4361-85a3-1e6a7d233315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Generally in a sequential CNN network there will be only one output layer at the end. \n",
        "#In the YOLO v3 architecture we are using there are multiple output layers giving out predictions.\n",
        "ln_all = net.getLayerNames()\n",
        "#print(ln)\n",
        "\n",
        "ln=[]\n",
        "# determine only the *output* layer names that we need from YOLO\n",
        "for i in ln_all:\n",
        "    if \"yolo\" in i:\n",
        "        ln.append(i)\n",
        "        \n",
        "print(ln)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yolo_82', 'yolo_94', 'yolo_106']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9DHf_wqp6or",
        "colab_type": "code",
        "outputId": "2d79b174-d9d6-499e-9e17-6def58fef98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# initialize the video stream, allow the cammera sensor to warmup and initialize the FPS counter\n",
        "print(\"[INFO] starting video stream...\")\n",
        "vs = VideoStream(src=0).start()\n",
        "time.sleep(2.0)\n",
        "fps = FPS().start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] starting video stream...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0vSiFTfWKqg4",
        "colab_type": "code",
        "outputId": "5e93e6d8-a75f-4817-9a7a-c864448dd77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # loop over frames from the video file stream\n",
        "    while True:\n",
        "        \n",
        "        # grab the frame from stream\n",
        "        frame = vs.read()\n",
        "        #resize it to have a maximum width of 400 pixels\n",
        "        frame = imutils.resize(frame, width=400)\n",
        "\n",
        "        (H, W) = frame.shape[:2]\n",
        "\n",
        "        # construct a blob from the input frame\n",
        "        #why we do : preprocessing images and preparing them for classification via pre-trained deep learning models.\n",
        "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
        "\n",
        "        net.setInput(blob)\n",
        "\n",
        "        #perform a forward pass of the YOLO object detector, giving us our bounding boxes and associated probabilities\n",
        "        layerOutputs = net.forward(ln)\n",
        "\n",
        "        #yolo has now processed our image and got the data. we now just need to fetch that data\n",
        "        # initialize empty lists\n",
        "        boxes = []\n",
        "        confidences = []\n",
        "        classIDs = []\n",
        "\n",
        "        #Let’s begin populating these lists with data from our YOLO layerOutputs\n",
        "        # loop over each of the layer outputs\n",
        "        for output in layerOutputs:\n",
        "            # loop over each of the detections\n",
        "            for detection in output:\n",
        "                # extract the class ID and confidence (i.e., probability) of the current object detection\n",
        "                scores = detection[5:]\n",
        "                classID = np.argmax(scores)\n",
        "                confidence = scores[classID]\n",
        "\n",
        "                # filter out weak predictions by ensuring the detected probability is greater than the minimum probability\n",
        "                if confidence > args[\"confidence\"]:\n",
        "                    # scale the bounding box coordinates back relative to the size of the image\n",
        "                    #YOLO returns the center (x, y)-coordinates of the bounding box followed by the box width and height\n",
        "                    box = detection[0:4] * np.array([W, H, W, H])\n",
        "\n",
        "                    #astype(\"int\") witll convert box values to int values\n",
        "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                    # use the center (x, y)-coordinates to derive the top-left corner of the bounding box\n",
        "                    x = int(centerX - (width / 2))\n",
        "                    y = int(centerY - (height / 2))\n",
        "\n",
        "                    # update our list of bounding box coordinates, confidences and class IDs\n",
        "                    boxes.append([x, y, int(width), int(height)])\n",
        "                    confidences.append(float(confidence))\n",
        "                    classIDs.append(classID)\n",
        "\n",
        "        # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
        "        #All that is required is that we submit our:\n",
        "        #bounding boxes , confidences , confidence threshold and NMS threshold\n",
        "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, args[\"confidence\"],args[\"threshold\"])\n",
        "\n",
        "        #idxs now hold indexes after non maxima suppression\n",
        "\n",
        "\n",
        "        #draw the boxes and class text on the frame\n",
        "        if len(idxs) > 0:\n",
        "            for i in idxs.flatten():\n",
        "                # extract the bounding box coordinates\n",
        "                (x, y) = (boxes[i][0], boxes[i][1]) #x,y--coordinate of top left corner\n",
        "                (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "                #pick the color\n",
        "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "\n",
        "                # draw a bounding box rectangle\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)  #2 is the line thickness\n",
        "\n",
        "                #prepare text\n",
        "                text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
        "\n",
        "                #put text on image at x, y-5....a bit up then the box\n",
        "                cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
        "\n",
        "        # show the output frame\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        " \n",
        "        # if the `q` key was pressed, break from the loop\n",
        "        if key == ord(\"q\"):\n",
        "            break\n",
        " \n",
        "        # update the FPS counter\n",
        "        fps.update()\n",
        "\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# release the file pointers\n",
        "# stop the timer and display FPS information\n",
        "fps.stop()\n",
        "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
        "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
        " \n",
        "# do a bit of cleanup\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] elapsed time: 55.21\n",
            "[INFO] approx. FPS: 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}